{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled93.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOBzmiU9nVTqk5yn4SETO8O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hamza1122/ML-OPT/blob/master/Untitled93.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3JCiHHn_dRP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "83e20fcd-3d20-4a95-eea9-5fc1f5c29622"
      },
      "source": [
        "!pip install optuna\n",
        "import pkg_resources\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "import optuna"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/32/266d4afd269e3ecd7fcc595937c1733f65eae6c09c3caea74c0de0b88d78/optuna-1.5.0.tar.gz (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 7.6MB/s \n",
            "\u001b[?25hCollecting alembic\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/1e/cabc75a189de0fbb2841d0975243e59bde8b7822bacbb95008ac6fe9ad47/alembic-1.4.2.tar.gz (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 16.4MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cliff\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/59/4db149d8962dc29a37c8bc08cd79185935527af9a27259a2d80cac707212/cliff-3.3.0-py3-none-any.whl (81kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 8.0MB/s \n",
            "\u001b[?25hCollecting cmaes>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/0e/7f/ebba8a7950487c760c245168f7ba318b35bf0cac9c0eba30b9fb50150a20/cmaes-0.5.1-py3-none-any.whl\n",
            "Collecting colorlog\n",
            "  Downloading https://files.pythonhosted.org/packages/00/0d/22c73c2eccb21dd3498df7d22c0b1d4a30f5a5fb3feb64e1ce06bc247747/colorlog-4.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from optuna) (0.15.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from optuna) (1.18.5)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (1.3.17)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from optuna) (4.41.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from alembic->optuna) (2.8.1)\n",
            "Collecting Mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/37/0e706200d22172eb8fa17d68a7ae22dec7631a0a92266634fb518a88a5b2/Mako-1.1.3-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 7.1MB/s \n",
            "\u001b[?25hCollecting python-editor>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
            "Requirement already satisfied: pyparsing>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (2.4.7)\n",
            "Collecting stevedore>=1.20.0\n",
            "  Downloading https://files.pythonhosted.org/packages/45/62/aa4c77e0f0899b7697445d8126fd099473452488d70f877426812c2ce982/stevedore-2.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (3.13)\n",
            "Collecting cmd2!=0.8.3,>=0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/b2/440d8d89b432b250c8f4db4368301aa7c6b49ab48a87b42e2a36f60c104d/cmd2-1.1.0-py3-none-any.whl (120kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 52.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: PrettyTable<0.8,>=0.7.2 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (0.7.2)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/ba/aa953a11ec014b23df057ecdbc922fdb40ca8463466b1193f3367d2711a6/pbr-5.4.5-py2.py3-none-any.whl (110kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 51.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (1.12.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from Mako->alembic->optuna) (1.1.1)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (19.3.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (0.2.5)\n",
            "Collecting colorama>=0.3.7\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: setuptools>=34.4 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (47.3.1)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/f6/5b/55866e1cde0f86f5eec59dab5de8a66628cb0d53da74b8dbc15ad8dabda3/pyperclip-1.8.0.tar.gz\n",
            "Building wheels for collected packages: alembic\n",
            "  Building wheel for alembic (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for alembic: filename=alembic-1.4.2-cp36-none-any.whl size=159543 sha256=4f12f1c026769b453738b205722c7b00764a92dde76659d0ca18bcad77cc279b\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/04/83/76023f7a4c14688c0b5c2682a96392cfdd3ee4449eaaa287ef\n",
            "Successfully built alembic\n",
            "Building wheels for collected packages: optuna, pyperclip\n",
            "  Building wheel for optuna (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for optuna: filename=optuna-1.5.0-cp36-none-any.whl size=276145 sha256=4fe346906c05e5695f6402b261c3c1b7ca71dbe408bddd6f081631c01b5543ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/38/21/78/4f5529e0c757ababc4217eb9adf1886d21eb22bb1ab98c33c5\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.0-cp36-none-any.whl size=8693 sha256=9588a2c7c9772c1a2d1ef9c01107f4e27c41429fc5c6fcbbc2cc95badf60d738\n",
            "  Stored in directory: /root/.cache/pip/wheels/b2/ac/0a/b784f0afe26eaf52e88a7e15c7369090deea0354fa1c6fc689\n",
            "Successfully built optuna pyperclip\n",
            "Installing collected packages: Mako, python-editor, alembic, pbr, stevedore, colorama, pyperclip, cmd2, cliff, cmaes, colorlog, optuna\n",
            "Successfully installed Mako-1.1.3 alembic-1.4.2 cliff-3.3.0 cmaes-0.5.1 cmd2-1.1.0 colorama-0.4.3 colorlog-4.1.0 optuna-1.5.0 pbr-5.4.5 pyperclip-1.8.0 python-editor-1.0.4 stevedore-2.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omRwEgF3_iki",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if pkg_resources.parse_version(tf.__version__) < pkg_resources.parse_version(\"2.0.0\"):\n",
        "    raise RuntimeError(\"tensorflow>=2.0.0 is required for this example.\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThBaIR3D_-UJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N_TRAIN_EXAMPLES = 3000\n",
        "N_VALID_EXAMPLES = 1000\n",
        "BATCHSIZE = 128\n",
        "CLASSES = 10\n",
        "EPOCHS = 1\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdOe7rUJAB-H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(trial):\n",
        "    # We optimize the numbers of layers, their units and weight decay parameter.\n",
        "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
        "    weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-10, 1e-3)\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    for i in range(n_layers):\n",
        "        num_hidden = int(trial.suggest_loguniform(\"n_units_l{}\".format(i), 4, 128))\n",
        "        model.add(\n",
        "            tf.keras.layers.Dense(\n",
        "                num_hidden,\n",
        "                activation=\"relu\",\n",
        "                kernel_regularizer=tf.keras.regularizers.l2(weight_decay),\n",
        "            )\n",
        "        )\n",
        "    model.add(\n",
        "        tf.keras.layers.Dense(CLASSES, kernel_regularizer=tf.keras.regularizers.l2(weight_decay))\n",
        "    )\n",
        "    return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09JeFq2WAEZs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def create_optimizer(trial):\n",
        "    # We optimize the choice of optimizers as well as their parameters.\n",
        "    kwargs = {}\n",
        "    optimizer_options = [\"RMSprop\", \"Adam\", \"SGD\"]\n",
        "    optimizer_selected = trial.suggest_categorical(\"optimizer\", optimizer_options)\n",
        "    if optimizer_selected == \"RMSprop\":\n",
        "        kwargs[\"learning_rate\"] = trial.suggest_loguniform(\"rmsprop_learning_rate\", 1e-5, 1e-1)\n",
        "        kwargs[\"decay\"] = trial.suggest_uniform(\"rmsprop_decay\", 0.85, 0.99)\n",
        "        kwargs[\"momentum\"] = trial.suggest_loguniform(\"rmsprop_momentum\", 1e-5, 1e-1)\n",
        "    elif optimizer_selected == \"Adam\":\n",
        "        kwargs[\"learning_rate\"] = trial.suggest_loguniform(\"adam_learning_rate\", 1e-5, 1e-1)\n",
        "    elif optimizer_selected == \"SGD\":\n",
        "        kwargs[\"learning_rate\"] = trial.suggest_loguniform(\"sgd_opt_learning_rate\", 1e-5, 1e-1)\n",
        "        kwargs[\"momentum\"] = trial.suggest_loguniform(\"sgd_opt_momentum\", 1e-5, 1e-1)\n",
        "\n",
        "    optimizer = getattr(tf.optimizers, optimizer_selected)(**kwargs)\n",
        "    return optimizer\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uzb23CE_AGX_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def learn(model, optimizer, dataset, mode=\"eval\"):\n",
        "    accuracy = tf.metrics.Accuracy(\"accuracy\", dtype=tf.float32)\n",
        "\n",
        "    for batch, (images, labels) in enumerate(dataset):\n",
        "        with tf.GradientTape() as tape:\n",
        "            logits = model(images, training=(mode == \"train\"))\n",
        "            loss_value = tf.reduce_mean(\n",
        "                tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels)\n",
        "            )\n",
        "            if mode == \"eval\":\n",
        "                accuracy(\n",
        "                    tf.argmax(logits, axis=1, output_type=tf.int64), tf.cast(labels, tf.int64)\n",
        "                )\n",
        "            else:\n",
        "                grads = tape.gradient(loss_value, model.variables)\n",
        "                optimizer.apply_gradients(zip(grads, model.variables))\n",
        "\n",
        "    if mode == \"eval\":\n",
        "        return accuracy"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kZDmLiCAISV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_mnist():\n",
        "    (x_train, y_train), (x_valid, y_valid) = mnist.load_data()\n",
        "    x_train = x_train.astype(\"float32\") / 255\n",
        "    x_valid = x_valid.astype(\"float32\") / 255\n",
        "\n",
        "    y_train = y_train.astype(\"int32\")\n",
        "    y_valid = y_valid.astype(\"int32\")\n",
        "\n",
        "    train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "    train_ds = train_ds.shuffle(60000).batch(BATCHSIZE).take(N_TRAIN_EXAMPLES)\n",
        "\n",
        "    valid_ds = tf.data.Dataset.from_tensor_slices((x_valid, y_valid))\n",
        "    valid_ds = valid_ds.shuffle(10000).batch(BATCHSIZE).take(N_VALID_EXAMPLES)\n",
        "    return train_ds, valid_ds"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKKBi5CJAJyO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def objective(trial):\n",
        "    # Get MNIST data.\n",
        "    train_ds, valid_ds = get_mnist()\n",
        "\n",
        "    # Build model and optimizer.\n",
        "    model = create_model(trial)\n",
        "    optimizer = create_optimizer(trial)\n",
        "\n",
        "    # Training and validating cycle.\n",
        "    with tf.device(\"/cpu:0\"):\n",
        "        for _ in range(EPOCHS):\n",
        "            learn(model, optimizer, train_ds, \"train\")\n",
        "\n",
        "        accuracy = learn(model, optimizer, valid_ds, \"eval\")\n",
        "\n",
        "    # Return last validation accuracy.\n",
        "    return accuracy.result()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgHGool4AL-G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "61922596-933b-436a-c78e-09e07c5eca0d"
      },
      "source": [
        "\n",
        "if __name__ == \"__main__\":\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective, n_trials=100)\n",
        "\n",
        "    print(\"Number of finished trials: \", len(study.trials))\n",
        "\n",
        "    print(\"Best trial:\")\n",
        "    trial = study.best_trial\n",
        "\n",
        "    print(\"  Value: \", trial.value)\n",
        "\n",
        "    print(\"  Params: \")\n",
        "    for key, value in trial.params.items():\n",
        "        print(\"    {}: {}\".format(key, value))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-07-08 15:17:37,457] Finished trial#0 with value: 0.9034000039100647 with parameters: {'n_layers': 2, 'weight_decay': 8.613675947852758e-05, 'n_units_l0': 18.263383907264, 'n_units_l1': 14.947162093706797, 'optimizer': 'Adam', 'adam_learning_rate': 0.0006495963937251672}. Best is trial#0 with value: 0.9034000039100647.\n",
            "[I 2020-07-08 15:17:41,402] Finished trial#1 with value: 0.44850000739097595 with parameters: {'n_layers': 2, 'weight_decay': 0.00016163819366285686, 'n_units_l0': 112.44927285978598, 'n_units_l1': 23.856651286158524, 'optimizer': 'Adam', 'adam_learning_rate': 1.0639399197617546e-05}. Best is trial#0 with value: 0.9034000039100647.\n",
            "[I 2020-07-08 15:17:44,456] Finished trial#2 with value: 0.26249998807907104 with parameters: {'n_layers': 1, 'weight_decay': 2.3152834084900497e-06, 'n_units_l0': 14.688401019113314, 'optimizer': 'Adam', 'adam_learning_rate': 2.2627051649222854e-05}. Best is trial#0 with value: 0.9034000039100647.\n",
            "[I 2020-07-08 15:17:48,247] Finished trial#3 with value: 0.8141000270843506 with parameters: {'n_layers': 3, 'weight_decay': 0.00036918883513282645, 'n_units_l0': 66.50366761190735, 'n_units_l1': 71.42027573895317, 'n_units_l2': 9.794420559047483, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.020669979874763923, 'sgd_opt_momentum': 0.01339941068633155}. Best is trial#0 with value: 0.9034000039100647.\n",
            "[I 2020-07-08 15:17:51,153] Finished trial#4 with value: 0.8241999745368958 with parameters: {'n_layers': 1, 'weight_decay': 1.3737966107868583e-07, 'n_units_l0': 53.564880742625704, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.007107970285289822, 'sgd_opt_momentum': 1.0367814383793214e-05}. Best is trial#0 with value: 0.9034000039100647.\n",
            "[I 2020-07-08 15:17:54,335] Finished trial#5 with value: 0.10499999672174454 with parameters: {'n_layers': 2, 'weight_decay': 8.257265052527087e-06, 'n_units_l0': 44.342654613267506, 'n_units_l1': 5.930518121086212, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.00031727176686565625, 'sgd_opt_momentum': 0.0007984559529367424}. Best is trial#0 with value: 0.9034000039100647.\n",
            "[I 2020-07-08 15:17:57,824] Finished trial#6 with value: 0.09759999811649323 with parameters: {'n_layers': 2, 'weight_decay': 8.499006933996461e-08, 'n_units_l0': 64.31886671282042, 'n_units_l1': 4.146506918671976, 'optimizer': 'RMSprop', 'rmsprop_learning_rate': 3.262555489982461e-05, 'rmsprop_decay': 0.971998118025861, 'rmsprop_momentum': 0.015433423100364274}. Best is trial#0 with value: 0.9034000039100647.\n",
            "[I 2020-07-08 15:18:01,139] Finished trial#7 with value: 0.8328999876976013 with parameters: {'n_layers': 3, 'weight_decay': 9.398328937454338e-08, 'n_units_l0': 8.674278017206527, 'n_units_l1': 13.399699569947504, 'n_units_l2': 43.216159760292385, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.025674138871190653, 'sgd_opt_momentum': 1.904915518204785e-05}. Best is trial#0 with value: 0.9034000039100647.\n",
            "[I 2020-07-08 15:18:03,971] Finished trial#8 with value: 0.18940000236034393 with parameters: {'n_layers': 1, 'weight_decay': 6.820132035332118e-08, 'n_units_l0': 9.447051529789917, 'optimizer': 'RMSprop', 'rmsprop_learning_rate': 0.0006196383337131768, 'rmsprop_decay': 0.9590989500924285, 'rmsprop_momentum': 2.3681102740243727e-05}. Best is trial#0 with value: 0.9034000039100647.\n",
            "[I 2020-07-08 15:18:07,629] Finished trial#9 with value: 0.09920000284910202 with parameters: {'n_layers': 3, 'weight_decay': 9.722423402303862e-10, 'n_units_l0': 29.29106080406845, 'n_units_l1': 16.571694930056253, 'n_units_l2': 5.46766246289142, 'optimizer': 'RMSprop', 'rmsprop_learning_rate': 1.0179536060570836e-05, 'rmsprop_decay': 0.8847496336417142, 'rmsprop_momentum': 3.835161899691685e-05}. Best is trial#0 with value: 0.9034000039100647.\n",
            "[I 2020-07-08 15:18:10,939] Finished trial#10 with value: 0.7681000232696533 with parameters: {'n_layers': 2, 'weight_decay': 3.058738783449621e-05, 'n_units_l0': 4.04771633208438, 'n_units_l1': 60.65853802526396, 'optimizer': 'Adam', 'adam_learning_rate': 0.02597069741292812}. Best is trial#0 with value: 0.9034000039100647.\n",
            "[I 2020-07-08 15:18:14,311] Finished trial#11 with value: 0.09139999747276306 with parameters: {'n_layers': 3, 'weight_decay': 2.2318265228074274e-09, 'n_units_l0': 6.102316968174162, 'n_units_l1': 13.925410176492479, 'n_units_l2': 100.49032574938273, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 1.1303370125977806e-05, 'sgd_opt_momentum': 2.1905758782702145e-05}. Best is trial#0 with value: 0.9034000039100647.\n",
            "[I 2020-07-08 15:18:18,077] Finished trial#12 with value: 0.9078999757766724 with parameters: {'n_layers': 3, 'weight_decay': 1.0430224586018404e-06, 'n_units_l0': 14.707905019159648, 'n_units_l1': 8.807239056324452, 'n_units_l2': 60.43314011629372, 'optimizer': 'Adam', 'adam_learning_rate': 0.0012857953990266413}. Best is trial#12 with value: 0.9078999757766724.\n",
            "[I 2020-07-08 15:18:22,044] Finished trial#13 with value: 0.9075000286102295 with parameters: {'n_layers': 3, 'weight_decay': 1.3607228535579018e-06, 'n_units_l0': 19.767284966238048, 'n_units_l1': 6.821496108816827, 'n_units_l2': 119.34717260612435, 'optimizer': 'Adam', 'adam_learning_rate': 0.0011163256092325382}. Best is trial#12 with value: 0.9078999757766724.\n",
            "[I 2020-07-08 15:18:26,014] Finished trial#14 with value: 0.9085999727249146 with parameters: {'n_layers': 3, 'weight_decay': 1.3421867313915114e-06, 'n_units_l0': 29.37120109917681, 'n_units_l1': 6.85536595752209, 'n_units_l2': 120.30813739336286, 'optimizer': 'Adam', 'adam_learning_rate': 0.0016410411548960383}. Best is trial#14 with value: 0.9085999727249146.\n",
            "[I 2020-07-08 15:18:29,990] Finished trial#15 with value: 0.9132000207901001 with parameters: {'n_layers': 3, 'weight_decay': 1.034546144579868e-06, 'n_units_l0': 28.21720876442258, 'n_units_l1': 7.867010034471265, 'n_units_l2': 47.821732965795796, 'optimizer': 'Adam', 'adam_learning_rate': 0.0015193788533778656}. Best is trial#15 with value: 0.9132000207901001.\n",
            "[I 2020-07-08 15:18:33,974] Finished trial#16 with value: 0.944599986076355 with parameters: {'n_layers': 3, 'weight_decay': 6.9855161394637325e-09, 'n_units_l0': 35.50254947496969, 'n_units_l1': 34.410026628463, 'n_units_l2': 23.14677591527517, 'optimizer': 'Adam', 'adam_learning_rate': 0.009361541559094622}. Best is trial#16 with value: 0.944599986076355.\n",
            "[I 2020-07-08 15:18:38,536] Finished trial#17 with value: 0.9395999908447266 with parameters: {'n_layers': 3, 'weight_decay': 1.1828555165848755e-10, 'n_units_l0': 109.93109743550549, 'n_units_l1': 36.56621732425777, 'n_units_l2': 21.97375240011936, 'optimizer': 'Adam', 'adam_learning_rate': 0.03014759207847495}. Best is trial#16 with value: 0.944599986076355.\n",
            "[I 2020-07-08 15:18:43,108] Finished trial#18 with value: 0.3986000120639801 with parameters: {'n_layers': 3, 'weight_decay': 1.0971560433505683e-10, 'n_units_l0': 121.44729498340642, 'n_units_l1': 41.18421040443517, 'n_units_l2': 15.873189417116917, 'optimizer': 'Adam', 'adam_learning_rate': 0.0708401822233154}. Best is trial#16 with value: 0.944599986076355.\n",
            "[I 2020-07-08 15:18:47,246] Finished trial#19 with value: 0.954200029373169 with parameters: {'n_layers': 2, 'weight_decay': 4.441334124410927e-09, 'n_units_l0': 89.63445295175451, 'n_units_l1': 121.2587886985205, 'optimizer': 'Adam', 'adam_learning_rate': 0.014933648290626099}. Best is trial#19 with value: 0.954200029373169.\n",
            "[I 2020-07-08 15:18:50,687] Finished trial#20 with value: 0.9569000005722046 with parameters: {'n_layers': 1, 'weight_decay': 8.10394213753042e-09, 'n_units_l0': 85.11740460602583, 'optimizer': 'Adam', 'adam_learning_rate': 0.014162770316869801}. Best is trial#20 with value: 0.9569000005722046.\n",
            "[I 2020-07-08 15:18:53,959] Finished trial#21 with value: 0.9528999924659729 with parameters: {'n_layers': 1, 'weight_decay': 1.4771291236917713e-08, 'n_units_l0': 80.63668267449306, 'optimizer': 'Adam', 'adam_learning_rate': 0.008751002892995605}. Best is trial#20 with value: 0.9569000005722046.\n",
            "[I 2020-07-08 15:18:57,295] Finished trial#22 with value: 0.9537000060081482 with parameters: {'n_layers': 1, 'weight_decay': 1.1151208625659712e-08, 'n_units_l0': 79.19434897159896, 'optimizer': 'Adam', 'adam_learning_rate': 0.006613456233147086}. Best is trial#20 with value: 0.9569000005722046.\n",
            "[I 2020-07-08 15:19:00,841] Finished trial#23 with value: 0.9602000117301941 with parameters: {'n_layers': 1, 'weight_decay': 9.268551561410817e-10, 'n_units_l0': 92.6615396186992, 'optimizer': 'Adam', 'adam_learning_rate': 0.006012827372079825}. Best is trial#23 with value: 0.9602000117301941.\n",
            "[I 2020-07-08 15:19:04,358] Finished trial#24 with value: 0.8914999961853027 with parameters: {'n_layers': 1, 'weight_decay': 5.463538214291599e-10, 'n_units_l0': 91.41406113374555, 'optimizer': 'Adam', 'adam_learning_rate': 0.07738610979265866}. Best is trial#23 with value: 0.9602000117301941.\n",
            "[I 2020-07-08 15:19:08,118] Finished trial#25 with value: 0.9560999870300293 with parameters: {'n_layers': 2, 'weight_decay': 6.929610998935739e-10, 'n_units_l0': 45.020714229728675, 'n_units_l1': 116.14199577811038, 'optimizer': 'Adam', 'adam_learning_rate': 0.004839774240076266}. Best is trial#23 with value: 0.9602000117301941.\n",
            "[I 2020-07-08 15:19:11,255] Finished trial#26 with value: 0.8804000020027161 with parameters: {'n_layers': 1, 'weight_decay': 3.6255477296136233e-10, 'n_units_l0': 46.29766547332961, 'optimizer': 'RMSprop', 'rmsprop_learning_rate': 0.0881511408096742, 'rmsprop_decay': 0.8547561036755897, 'rmsprop_momentum': 0.07039870117625593}. Best is trial#23 with value: 0.9602000117301941.\n",
            "[I 2020-07-08 15:19:15,086] Finished trial#27 with value: 0.9596999883651733 with parameters: {'n_layers': 2, 'weight_decay': 1.5241407100527252e-09, 'n_units_l0': 59.208338943547055, 'n_units_l1': 115.97099471030927, 'optimizer': 'Adam', 'adam_learning_rate': 0.0033437681468198406}. Best is trial#23 with value: 0.9602000117301941.\n",
            "[I 2020-07-08 15:19:18,411] Finished trial#28 with value: 0.9161999821662903 with parameters: {'n_layers': 1, 'weight_decay': 2.1407444547152877e-08, 'n_units_l0': 70.76007398208317, 'optimizer': 'Adam', 'adam_learning_rate': 0.00032763559346638666}. Best is trial#23 with value: 0.9602000117301941.\n",
            "[I 2020-07-08 15:19:22,148] Finished trial#29 with value: 0.8981999754905701 with parameters: {'n_layers': 2, 'weight_decay': 1.857199077729724e-09, 'n_units_l0': 53.80730448642233, 'n_units_l1': 84.2307955140331, 'optimizer': 'Adam', 'adam_learning_rate': 0.0001541970152161723}. Best is trial#23 with value: 0.9602000117301941.\n",
            "[I 2020-07-08 15:19:25,715] Finished trial#30 with value: 0.958899974822998 with parameters: {'n_layers': 1, 'weight_decay': 1.9615428878077173e-10, 'n_units_l0': 101.77644732787273, 'optimizer': 'Adam', 'adam_learning_rate': 0.0033672162095785304}. Best is trial#23 with value: 0.9602000117301941.\n",
            "[I 2020-07-08 15:19:29,384] Finished trial#31 with value: 0.9606000185012817 with parameters: {'n_layers': 1, 'weight_decay': 1.4387595823954096e-10, 'n_units_l0': 122.86839758572357, 'optimizer': 'Adam', 'adam_learning_rate': 0.005630803920975541}. Best is trial#31 with value: 0.9606000185012817.\n",
            "[I 2020-07-08 15:19:33,011] Finished trial#32 with value: 0.9567000269889832 with parameters: {'n_layers': 1, 'weight_decay': 1.3468459479045198e-10, 'n_units_l0': 118.15856708487645, 'optimizer': 'Adam', 'adam_learning_rate': 0.0030425231328384057}. Best is trial#31 with value: 0.9606000185012817.\n",
            "[I 2020-07-08 15:19:36,670] Finished trial#33 with value: 0.9575999975204468 with parameters: {'n_layers': 1, 'weight_decay': 2.962112915564287e-10, 'n_units_l0': 125.23100360049469, 'optimizer': 'Adam', 'adam_learning_rate': 0.0032852764571612712}. Best is trial#31 with value: 0.9606000185012817.\n",
            "[I 2020-07-08 15:19:40,702] Finished trial#34 with value: 0.9570000171661377 with parameters: {'n_layers': 2, 'weight_decay': 2.000232826190136e-10, 'n_units_l0': 98.95447883693265, 'n_units_l1': 47.77852309338041, 'optimizer': 'Adam', 'adam_learning_rate': 0.002416450522969963}. Best is trial#31 with value: 0.9606000185012817.\n",
            "[I 2020-07-08 15:19:44,366] Finished trial#35 with value: 0.9634000062942505 with parameters: {'n_layers': 1, 'weight_decay': 2.040502121258563e-09, 'n_units_l0': 127.62059899054914, 'optimizer': 'Adam', 'adam_learning_rate': 0.0048151919527598406}. Best is trial#35 with value: 0.9634000062942505.\n",
            "[I 2020-07-08 15:19:48,141] Finished trial#36 with value: 0.9214000105857849 with parameters: {'n_layers': 1, 'weight_decay': 2.782239879223271e-09, 'n_units_l0': 126.28565887537687, 'optimizer': 'Adam', 'adam_learning_rate': 0.0004510663856236289}. Best is trial#35 with value: 0.9634000062942505.\n",
            "[I 2020-07-08 15:19:51,919] Finished trial#37 with value: 0.9259999990463257 with parameters: {'n_layers': 2, 'weight_decay': 1.1372060686280431e-09, 'n_units_l0': 65.9459301336164, 'n_units_l1': 96.15529548737051, 'optimizer': 'Adam', 'adam_learning_rate': 0.02451148464096946}. Best is trial#35 with value: 0.9634000062942505.\n",
            "[I 2020-07-08 15:19:54,816] Finished trial#38 with value: 0.13899999856948853 with parameters: {'n_layers': 1, 'weight_decay': 3.273162071296893e-08, 'n_units_l0': 54.81517618753901, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 1.2151058310837447e-05, 'sgd_opt_momentum': 0.017845932579703523}. Best is trial#35 with value: 0.9634000062942505.\n",
            "[I 2020-07-08 15:19:58,805] Finished trial#39 with value: 0.886900007724762 with parameters: {'n_layers': 2, 'weight_decay': 4.048217208848542e-07, 'n_units_l0': 126.57714418204024, 'n_units_l1': 27.12291859308278, 'optimizer': 'RMSprop', 'rmsprop_learning_rate': 0.07636938861454184, 'rmsprop_decay': 0.9225999274967714, 'rmsprop_momentum': 0.0009060288123864967}. Best is trial#35 with value: 0.9634000062942505.\n",
            "[I 2020-07-08 15:20:02,007] Finished trial#40 with value: 0.9470000267028809 with parameters: {'n_layers': 1, 'weight_decay': 1.2641967120844727e-09, 'n_units_l0': 38.021403240578735, 'optimizer': 'Adam', 'adam_learning_rate': 0.005506495334761451}. Best is trial#35 with value: 0.9634000062942505.\n",
            "[I 2020-07-08 15:20:05,855] Finished trial#41 with value: 0.9563999772071838 with parameters: {'n_layers': 1, 'weight_decay': 3.3205024220706696e-10, 'n_units_l0': 100.1128456512013, 'optimizer': 'Adam', 'adam_learning_rate': 0.003588600244894638}. Best is trial#35 with value: 0.9634000062942505.\n",
            "[I 2020-07-08 15:20:09,622] Finished trial#42 with value: 0.9322999715805054 with parameters: {'n_layers': 1, 'weight_decay': 3.756128840589957e-09, 'n_units_l0': 103.7202348828534, 'optimizer': 'Adam', 'adam_learning_rate': 0.0006706661728972804}. Best is trial#35 with value: 0.9634000062942505.\n",
            "[I 2020-07-08 15:20:12,926] Finished trial#43 with value: 0.9546999931335449 with parameters: {'n_layers': 1, 'weight_decay': 5.486671177515934e-10, 'n_units_l0': 72.809965194496, 'optimizer': 'Adam', 'adam_learning_rate': 0.011892015168592812}. Best is trial#35 with value: 0.9634000062942505.\n",
            "[I 2020-07-08 15:20:16,212] Finished trial#44 with value: 0.940500020980835 with parameters: {'n_layers': 1, 'weight_decay': 1.1995941254704798e-10, 'n_units_l0': 58.017570813028264, 'optimizer': 'Adam', 'adam_learning_rate': 0.0019881890500924523}. Best is trial#35 with value: 0.9634000062942505.\n",
            "[I 2020-07-08 15:20:19,836] Finished trial#45 with value: 0.1356000006198883 with parameters: {'n_layers': 2, 'weight_decay': 2.3835309159859164e-10, 'n_units_l0': 98.3426412476498, 'n_units_l1': 61.126498817574, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.000313504906755464, 'sgd_opt_momentum': 0.000632458840926741}. Best is trial#35 with value: 0.9634000062942505.\n",
            "[I 2020-07-08 15:20:23,255] Finished trial#46 with value: 0.9567999839782715 with parameters: {'n_layers': 1, 'weight_decay': 1.2185633131428767e-09, 'n_units_l0': 65.12172256778372, 'optimizer': 'Adam', 'adam_learning_rate': 0.005335198061979513}. Best is trial#35 with value: 0.9634000062942505.\n",
            "[I 2020-07-08 15:20:27,033] Finished trial#47 with value: 0.8676999807357788 with parameters: {'n_layers': 2, 'weight_decay': 4.468835159693767e-09, 'n_units_l0': 78.27210436425949, 'n_units_l1': 125.76708027409542, 'optimizer': 'RMSprop', 'rmsprop_learning_rate': 0.003919459005820967, 'rmsprop_decay': 0.8513192721678114, 'rmsprop_momentum': 0.0013567430502185898}. Best is trial#35 with value: 0.9634000062942505.\n",
            "[I 2020-07-08 15:20:30,611] Finished trial#48 with value: 0.9351999759674072 with parameters: {'n_layers': 1, 'weight_decay': 2.9477617929414698e-08, 'n_units_l0': 112.4304947373069, 'optimizer': 'Adam', 'adam_learning_rate': 0.0007331902609710223}. Best is trial#35 with value: 0.9634000062942505.\n",
            "[I 2020-07-08 15:20:34,621] Finished trial#49 with value: 0.9373999834060669 with parameters: {'n_layers': 2, 'weight_decay': 1.9993308151679407e-07, 'n_units_l0': 88.85398400485845, 'n_units_l1': 51.89545739536175, 'optimizer': 'Adam', 'adam_learning_rate': 0.03376834014416313}. Best is trial#35 with value: 0.9634000062942505.\n",
            "[I 2020-07-08 15:20:37,995] Finished trial#50 with value: 0.6883000135421753 with parameters: {'n_layers': 1, 'weight_decay': 6.074750938900645e-10, 'n_units_l0': 110.26796421189539, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.0021080340358693777, 'sgd_opt_momentum': 0.09260837845641925}. Best is trial#35 with value: 0.9634000062942505.\n",
            "[I 2020-07-08 15:20:41,803] Finished trial#51 with value: 0.9603999853134155 with parameters: {'n_layers': 1, 'weight_decay': 3.0692242701726517e-10, 'n_units_l0': 123.44014822293128, 'optimizer': 'Adam', 'adam_learning_rate': 0.003427933931197409}. Best is trial#35 with value: 0.9634000062942505.\n",
            "[I 2020-07-08 15:20:45,574] Finished trial#52 with value: 0.9559000134468079 with parameters: {'n_layers': 1, 'weight_decay': 1.7970804137404252e-09, 'n_units_l0': 122.19222769330524, 'optimizer': 'Adam', 'adam_learning_rate': 0.0035634985830031735}. Best is trial#35 with value: 0.9634000062942505.\n",
            "[I 2020-07-08 15:20:49,465] Finished trial#53 with value: 0.9660000205039978 with parameters: {'n_layers': 1, 'weight_decay': 1.642893898489407e-10, 'n_units_l0': 126.15816158225437, 'optimizer': 'Adam', 'adam_learning_rate': 0.006810080278490901}. Best is trial#53 with value: 0.9660000205039978.\n",
            "[I 2020-07-08 15:20:53,254] Finished trial#54 with value: 0.9599999785423279 with parameters: {'n_layers': 1, 'weight_decay': 1.0384703244855959e-10, 'n_units_l0': 126.8911722182215, 'optimizer': 'Adam', 'adam_learning_rate': 0.0071366455049782385}. Best is trial#53 with value: 0.9660000205039978.\n",
            "[I 2020-07-08 15:20:57,017] Finished trial#55 with value: 0.9442999958992004 with parameters: {'n_layers': 1, 'weight_decay': 1.2956048503032783e-10, 'n_units_l0': 126.11483725544684, 'optimizer': 'Adam', 'adam_learning_rate': 0.01996254397788443}. Best is trial#53 with value: 0.9660000205039978.\n",
            "[I 2020-07-08 15:21:00,641] Finished trial#56 with value: 0.9616000056266785 with parameters: {'n_layers': 1, 'weight_decay': 7.321478019482107e-05, 'n_units_l0': 90.59905423074856, 'optimizer': 'Adam', 'adam_learning_rate': 0.008284948668914821}. Best is trial#53 with value: 0.9660000205039978.\n",
            "[I 2020-07-08 15:21:04,167] Finished trial#57 with value: 0.9610000252723694 with parameters: {'n_layers': 1, 'weight_decay': 0.0005277541959990595, 'n_units_l0': 84.1917859402724, 'optimizer': 'Adam', 'adam_learning_rate': 0.011126178695322047}. Best is trial#53 with value: 0.9660000205039978.\n",
            "[I 2020-07-08 15:21:07,244] Finished trial#58 with value: 0.8738999962806702 with parameters: {'n_layers': 1, 'weight_decay': 0.0003764741204233507, 'n_units_l0': 11.607237640859742, 'optimizer': 'Adam', 'adam_learning_rate': 0.04103699596748627}. Best is trial#53 with value: 0.9660000205039978.\n",
            "[I 2020-07-08 15:21:10,135] Finished trial#59 with value: 0.8557000160217285 with parameters: {'n_layers': 1, 'weight_decay': 0.0007754361910594026, 'n_units_l0': 4.907866011380473, 'optimizer': 'Adam', 'adam_learning_rate': 0.010225954668640914}. Best is trial#53 with value: 0.9660000205039978.\n",
            "[I 2020-07-08 15:21:13,775] Finished trial#60 with value: 0.9416000247001648 with parameters: {'n_layers': 1, 'weight_decay': 5.07907068193745e-05, 'n_units_l0': 81.90753494761448, 'optimizer': 'Adam', 'adam_learning_rate': 0.0013446178847365234}. Best is trial#53 with value: 0.9660000205039978.\n",
            "[I 2020-07-08 15:21:17,412] Finished trial#61 with value: 0.9610999822616577 with parameters: {'n_layers': 1, 'weight_decay': 1.168689785466641e-05, 'n_units_l0': 90.6595554732156, 'optimizer': 'Adam', 'adam_learning_rate': 0.014919522732168356}. Best is trial#53 with value: 0.9660000205039978.\n",
            "[I 2020-07-08 15:21:20,897] Finished trial#62 with value: 0.9524999856948853 with parameters: {'n_layers': 1, 'weight_decay': 1.3067544738966492e-05, 'n_units_l0': 73.70437416491426, 'optimizer': 'Adam', 'adam_learning_rate': 0.01730633371826321}. Best is trial#53 with value: 0.9660000205039978.\n",
            "[I 2020-07-08 15:21:24,508] Finished trial#63 with value: 0.9549000263214111 with parameters: {'n_layers': 1, 'weight_decay': 0.00016221991610941122, 'n_units_l0': 112.03208725824067, 'optimizer': 'Adam', 'adam_learning_rate': 0.01137286253990443}. Best is trial#53 with value: 0.9660000205039978.\n",
            "[I 2020-07-08 15:21:28,131] Finished trial#64 with value: 0.965499997138977 with parameters: {'n_layers': 1, 'weight_decay': 1.7991883672582425e-05, 'n_units_l0': 87.0477389602733, 'optimizer': 'Adam', 'adam_learning_rate': 0.008618335928022573}. Best is trial#53 with value: 0.9660000205039978.\n",
            "[I 2020-07-08 15:21:31,702] Finished trial#65 with value: 0.920199990272522 with parameters: {'n_layers': 1, 'weight_decay': 3.8145606137616538e-06, 'n_units_l0': 84.33609928375328, 'optimizer': 'Adam', 'adam_learning_rate': 0.04964507183144424}. Best is trial#53 with value: 0.9660000205039978.\n",
            "[I 2020-07-08 15:21:34,981] Finished trial#66 with value: 0.9337999820709229 with parameters: {'n_layers': 1, 'weight_decay': 1.3191083314245688e-05, 'n_units_l0': 23.67983025642968, 'optimizer': 'Adam', 'adam_learning_rate': 0.00861297836227323}. Best is trial#53 with value: 0.9660000205039978.\n",
            "[I 2020-07-08 15:21:38,182] Finished trial#67 with value: 0.2402999997138977 with parameters: {'n_layers': 1, 'weight_decay': 0.00011730339489032713, 'n_units_l0': 50.14042892052153, 'optimizer': 'RMSprop', 'rmsprop_learning_rate': 0.00035344431342551494, 'rmsprop_decay': 0.9247189384805914, 'rmsprop_momentum': 0.00034475926853629816}. Best is trial#53 with value: 0.9660000205039978.\n",
            "[I 2020-07-08 15:21:41,611] Finished trial#68 with value: 0.955299973487854 with parameters: {'n_layers': 1, 'weight_decay': 4.480364648206506e-05, 'n_units_l0': 96.59891741933147, 'optimizer': 'Adam', 'adam_learning_rate': 0.016861920572304828}. Best is trial#53 with value: 0.9660000205039978.\n",
            "[I 2020-07-08 15:21:44,985] Finished trial#69 with value: 0.9535999894142151 with parameters: {'n_layers': 1, 'weight_decay': 0.0008858874674519523, 'n_units_l0': 73.54935825177853, 'optimizer': 'Adam', 'adam_learning_rate': 0.007624629870713409}. Best is trial#53 with value: 0.9660000205039978.\n",
            "[I 2020-07-08 15:21:48,238] Finished trial#70 with value: 0.9474999904632568 with parameters: {'n_layers': 1, 'weight_decay': 3.96991595176126e-06, 'n_units_l0': 63.2601292692796, 'optimizer': 'Adam', 'adam_learning_rate': 0.0222837379959715}. Best is trial#53 with value: 0.9660000205039978.\n",
            "[I 2020-07-08 15:21:51,907] Finished trial#71 with value: 0.960099995136261 with parameters: {'n_layers': 1, 'weight_decay': 0.00023575773686601424, 'n_units_l0': 108.57021484040251, 'optimizer': 'Adam', 'adam_learning_rate': 0.011644699916975889}. Best is trial#53 with value: 0.9660000205039978.\n",
            "[I 2020-07-08 15:21:55,530] Finished trial#72 with value: 0.9546999931335449 with parameters: {'n_layers': 1, 'weight_decay': 3.309076309134261e-05, 'n_units_l0': 91.66231026888471, 'optimizer': 'Adam', 'adam_learning_rate': 0.004772572770979101}. Best is trial#53 with value: 0.9660000205039978.\n",
            "[I 2020-07-08 15:21:59,192] Finished trial#73 with value: 0.9532999992370605 with parameters: {'n_layers': 1, 'weight_decay': 1.699194977850788e-05, 'n_units_l0': 113.23320176456056, 'optimizer': 'Adam', 'adam_learning_rate': 0.0021366853406213173}. Best is trial#53 with value: 0.9660000205039978.\n",
            "[I 2020-07-08 15:22:02,718] Finished trial#74 with value: 0.9552000164985657 with parameters: {'n_layers': 1, 'weight_decay': 6.238966612512263e-05, 'n_units_l0': 90.00837386248602, 'optimizer': 'Adam', 'adam_learning_rate': 0.004524836139990152}. Best is trial#53 with value: 0.9660000205039978.\n",
            "[I 2020-07-08 15:22:06,060] Finished trial#75 with value: 0.9557999968528748 with parameters: {'n_layers': 1, 'weight_decay': 0.000557825960829789, 'n_units_l0': 80.997028123081, 'optimizer': 'Adam', 'adam_learning_rate': 0.009198629040915316}. Best is trial#53 with value: 0.9660000205039978.\n",
            "[I 2020-07-08 15:22:09,568] Finished trial#76 with value: 0.9649999737739563 with parameters: {'n_layers': 1, 'weight_decay': 7.797458972649378e-06, 'n_units_l0': 104.08087183360296, 'optimizer': 'Adam', 'adam_learning_rate': 0.006618142591854779}. Best is trial#53 with value: 0.9660000205039978.\n",
            "[I 2020-07-08 15:22:13,228] Finished trial#77 with value: 0.9526000022888184 with parameters: {'n_layers': 1, 'weight_decay': 2.2506323485795887e-05, 'n_units_l0': 103.80407426630602, 'optimizer': 'Adam', 'adam_learning_rate': 0.01357384435631199}. Best is trial#53 with value: 0.9660000205039978.\n",
            "[I 2020-07-08 15:22:16,215] Finished trial#78 with value: 0.91839998960495 with parameters: {'n_layers': 1, 'weight_decay': 7.162046140574143e-06, 'n_units_l0': 66.8772899142877, 'optimizer': 'SGD', 'sgd_opt_learning_rate': 0.09254457879912754, 'sgd_opt_momentum': 0.00010797616151325558}. Best is trial#53 with value: 0.9660000205039978.\n",
            "[I 2020-07-08 15:22:19,765] Finished trial#79 with value: 0.9616000056266785 with parameters: {'n_layers': 1, 'weight_decay': 6.202276314777746e-07, 'n_units_l0': 95.40530499262177, 'optimizer': 'Adam', 'adam_learning_rate': 0.006789227256843177}. Best is trial#53 with value: 0.9660000205039978.\n",
            "[I 2020-07-08 15:22:23,120] Finished trial#80 with value: 0.9415000081062317 with parameters: {'n_layers': 1, 'weight_decay': 5.851826635996625e-06, 'n_units_l0': 76.55852408580193, 'optimizer': 'Adam', 'adam_learning_rate': 0.029784350420665587}. Best is trial#53 with value: 0.9660000205039978.\n",
            "[I 2020-07-08 15:22:26,558] Finished trial#81 with value: 0.9609000086784363 with parameters: {'n_layers': 1, 'weight_decay': 5.188750012126555e-07, 'n_units_l0': 96.13484421092996, 'optimizer': 'Adam', 'adam_learning_rate': 0.006933155301375439}. Best is trial#53 with value: 0.9660000205039978.\n",
            "[I 2020-07-08 15:22:30,069] Finished trial#82 with value: 0.961899995803833 with parameters: {'n_layers': 1, 'weight_decay': 1.393799692816573e-06, 'n_units_l0': 87.45320119727054, 'optimizer': 'Adam', 'adam_learning_rate': 0.008407369743866537}. Best is trial#53 with value: 0.9660000205039978.\n",
            "[I 2020-07-08 15:22:33,584] Finished trial#83 with value: 0.9549000263214111 with parameters: {'n_layers': 1, 'weight_decay': 1.8878861672917385e-06, 'n_units_l0': 86.99350588565257, 'optimizer': 'Adam', 'adam_learning_rate': 0.015133861357906717}. Best is trial#53 with value: 0.9660000205039978.\n",
            "[I 2020-07-08 15:22:36,985] Finished trial#84 with value: 0.9574999809265137 with parameters: {'n_layers': 1, 'weight_decay': 9.551762393978872e-07, 'n_units_l0': 83.97837853915385, 'optimizer': 'Adam', 'adam_learning_rate': 0.008680153689216775}. Best is trial#53 with value: 0.9660000205039978.\n",
            "[I 2020-07-08 15:22:40,227] Finished trial#85 with value: 0.9602000117301941 with parameters: {'n_layers': 1, 'weight_decay': 6.046281625454105e-07, 'n_units_l0': 60.10888884049365, 'optimizer': 'Adam', 'adam_learning_rate': 0.006289701446761471}. Best is trial#53 with value: 0.9660000205039978.\n",
            "[I 2020-07-08 15:22:43,518] Finished trial#86 with value: 0.4262999892234802 with parameters: {'n_layers': 1, 'weight_decay': 3.317218333083586e-06, 'n_units_l0': 69.76368804475594, 'optimizer': 'Adam', 'adam_learning_rate': 1.1030667982985172e-05}. Best is trial#53 with value: 0.9660000205039978.\n",
            "[I 2020-07-08 15:22:47,142] Finished trial#87 with value: 0.9591000080108643 with parameters: {'n_layers': 1, 'weight_decay': 1.7564130345189665e-07, 'n_units_l0': 105.53395107807872, 'optimizer': 'Adam', 'adam_learning_rate': 0.0044380229594066945}. Best is trial#53 with value: 0.9660000205039978.\n",
            "[I 2020-07-08 15:22:50,635] Finished trial#88 with value: 0.8873999714851379 with parameters: {'n_layers': 1, 'weight_decay': 9.064190384239173e-06, 'n_units_l0': 95.506161767612, 'optimizer': 'RMSprop', 'rmsprop_learning_rate': 0.007560772047798658, 'rmsprop_decay': 0.889120738022696, 'rmsprop_momentum': 0.09849711402346334}. Best is trial#53 with value: 0.9660000205039978.\n",
            "[I 2020-07-08 15:22:53,967] Finished trial#89 with value: 0.9605000019073486 with parameters: {'n_layers': 1, 'weight_decay': 8.275866366468405e-05, 'n_units_l0': 77.85768188430256, 'optimizer': 'Adam', 'adam_learning_rate': 0.013233762069936676}. Best is trial#53 with value: 0.9660000205039978.\n",
            "[I 2020-07-08 15:22:57,718] Finished trial#90 with value: 0.9460999965667725 with parameters: {'n_layers': 1, 'weight_decay': 2.4146505646010005e-06, 'n_units_l0': 117.47335464326952, 'optimizer': 'Adam', 'adam_learning_rate': 0.019481410407960992}. Best is trial#53 with value: 0.9660000205039978.\n",
            "[I 2020-07-08 15:23:01,163] Finished trial#91 with value: 0.9599999785423279 with parameters: {'n_layers': 1, 'weight_decay': 1.1601189641977692e-07, 'n_units_l0': 96.6141826829902, 'optimizer': 'Adam', 'adam_learning_rate': 0.006208267855801998}. Best is trial#53 with value: 0.9660000205039978.\n",
            "[I 2020-07-08 15:23:04,643] Finished trial#92 with value: 0.9624000191688538 with parameters: {'n_layers': 1, 'weight_decay': 6.634631568032464e-07, 'n_units_l0': 104.90274840130581, 'optimizer': 'Adam', 'adam_learning_rate': 0.006914680521426353}. Best is trial#53 with value: 0.9660000205039978.\n",
            "[I 2020-07-08 15:23:08,272] Finished trial#93 with value: 0.9591000080108643 with parameters: {'n_layers': 1, 'weight_decay': 8.54926807467064e-07, 'n_units_l0': 105.78322942176082, 'optimizer': 'Adam', 'adam_learning_rate': 0.0025955259258090384}. Best is trial#53 with value: 0.9660000205039978.\n",
            "[I 2020-07-08 15:23:11,816] Finished trial#94 with value: 0.9613000154495239 with parameters: {'n_layers': 1, 'weight_decay': 2.978330553202466e-07, 'n_units_l0': 87.82852973183972, 'optimizer': 'Adam', 'adam_learning_rate': 0.010021503366658089}. Best is trial#53 with value: 0.9660000205039978.\n",
            "[I 2020-07-08 15:23:15,473] Finished trial#95 with value: 0.9591000080108643 with parameters: {'n_layers': 1, 'weight_decay': 2.4021899246257577e-07, 'n_units_l0': 114.88831321053124, 'optimizer': 'Adam', 'adam_learning_rate': 0.00851853347917574}. Best is trial#53 with value: 0.9660000205039978.\n",
            "[I 2020-07-08 15:23:18,909] Finished trial#96 with value: 0.9591000080108643 with parameters: {'n_layers': 1, 'weight_decay': 2.7447562740447777e-05, 'n_units_l0': 88.64343926850214, 'optimizer': 'Adam', 'adam_learning_rate': 0.004234620710670719}. Best is trial#53 with value: 0.9660000205039978.\n",
            "[I 2020-07-08 15:23:22,535] Finished trial#97 with value: 0.9628000259399414 with parameters: {'n_layers': 1, 'weight_decay': 1.6026628272254932e-06, 'n_units_l0': 101.76606837295009, 'optimizer': 'Adam', 'adam_learning_rate': 0.007014257105911214}. Best is trial#53 with value: 0.9660000205039978.\n",
            "[I 2020-07-08 15:23:26,141] Finished trial#98 with value: 0.8668000102043152 with parameters: {'n_layers': 1, 'weight_decay': 1.5446064653553513e-06, 'n_units_l0': 99.34016932141249, 'optimizer': 'Adam', 'adam_learning_rate': 7.777190511288439e-05}. Best is trial#53 with value: 0.9660000205039978.\n",
            "[I 2020-07-08 15:23:29,788] Finished trial#99 with value: 0.9538000226020813 with parameters: {'n_layers': 1, 'weight_decay': 6.115468995846695e-08, 'n_units_l0': 118.07964106864955, 'optimizer': 'Adam', 'adam_learning_rate': 0.005777056123436819}. Best is trial#53 with value: 0.9660000205039978.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Number of finished trials:  100\n",
            "Best trial:\n",
            "  Value:  0.9660000205039978\n",
            "  Params: \n",
            "    n_layers: 1\n",
            "    weight_decay: 1.642893898489407e-10\n",
            "    n_units_l0: 126.15816158225437\n",
            "    optimizer: Adam\n",
            "    adam_learning_rate: 0.006810080278490901\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCY6CQ0_ANpi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}